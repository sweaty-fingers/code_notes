{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 레이어 가중치 임의로 초기화 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## weight 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(28, 512)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_class = 28\n",
    "n_dim = 512\n",
    "embedding = nn.Embedding(n_class, n_dim)\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0274,  0.0130, -0.0493,  ...,  0.0409, -0.0268,  0.0271],\n",
       "        [-0.0086, -0.0320,  0.0854,  ...,  0.0927, -0.0167, -0.0975],\n",
       "        [-0.0279,  0.0317,  0.0057,  ...,  0.0772, -0.0510, -0.0687],\n",
       "        ...,\n",
       "        [-0.0599,  0.0246, -0.0251,  ..., -0.0921,  0.0598,  0.0282],\n",
       "        [ 0.0171, -0.0007,  0.0151,  ...,  0.0915, -0.0467,  0.0437],\n",
       "        [ 0.0012, -0.0283, -0.0981,  ...,  0.0369, -0.0250, -0.0390]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_range = 0.1\n",
    "# 범위 내의 uniform distribution으로 가중치 초기화\n",
    "embedding.weight.data.uniform_(-init_range, init_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0274,  0.0130, -0.0493,  ...,  0.0409, -0.0268,  0.0271],\n",
       "        [-0.0086, -0.0320,  0.0854,  ...,  0.0927, -0.0167, -0.0975],\n",
       "        [-0.0279,  0.0317,  0.0057,  ...,  0.0772, -0.0510, -0.0687],\n",
       "        ...,\n",
       "        [-0.0599,  0.0246, -0.0251,  ..., -0.0921,  0.0598,  0.0282],\n",
       "        [ 0.0171, -0.0007,  0.0151,  ...,  0.0915, -0.0467,  0.0437],\n",
       "        [ 0.0012, -0.0283, -0.0981,  ...,  0.0369, -0.0250, -0.0390]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=7, out_features=12, bias=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = 7\n",
    "output_dim = 12\n",
    "\n",
    "fc = nn.Linear(input_dim, output_dim)\n",
    "fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.1163,  0.3046, -0.1006,  0.2548,  0.1786,  0.1081,  0.3656],\n",
       "        [ 0.3279,  0.2114, -0.0131, -0.3168, -0.1481, -0.1592,  0.0870],\n",
       "        [ 0.0794,  0.1264,  0.1920,  0.0260, -0.3559, -0.2213, -0.1615],\n",
       "        [-0.1733, -0.1112, -0.0250,  0.3229,  0.1303,  0.0174, -0.0056],\n",
       "        [-0.2000, -0.2292, -0.3580,  0.1053, -0.2243,  0.0454, -0.1451],\n",
       "        [-0.2339,  0.0474, -0.0082, -0.1234,  0.0384, -0.0079,  0.0814],\n",
       "        [ 0.2550,  0.3175,  0.3719,  0.1353,  0.0593,  0.1334,  0.0893],\n",
       "        [ 0.2902,  0.0825,  0.3769,  0.2871,  0.3054,  0.0654,  0.1672],\n",
       "        [-0.0549,  0.2630, -0.0087, -0.0521, -0.2486, -0.0694,  0.0192],\n",
       "        [-0.1748, -0.1113, -0.0085,  0.2610,  0.1529, -0.0268, -0.2390],\n",
       "        [ 0.2100, -0.3631,  0.2365, -0.1804,  0.2873,  0.3607,  0.3773],\n",
       "        [ 0.1979, -0.1182, -0.1451,  0.2423,  0.0529, -0.1993,  0.2752]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.0366, -0.1610,  0.0843, -0.0288,  0.3416,  0.1482, -0.0821, -0.0371,\n",
       "        -0.3617,  0.3198, -0.0633, -0.0912], requires_grad=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc.bias # n_bias == output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bias 0으로 초기화\n",
    "fc.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc.bias.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kaiming_normal_\n",
    "(https://pytorch.org/docs/stable/nn.init.html#torch.nn.init.kaiming_normal_)\n",
    "Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification - He, K. et al. (2015) 에서 제안한 방식으로 값을 채운다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2, 1, 1])\n",
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "conv_input_dim = 2\n",
    "conv_output_dim = 4\n",
    "kernel_size = 1\n",
    "encoder_projection = nn.Conv2d(conv_input_dim, conv_output_dim, kernel_size=kernel_size)\n",
    "\n",
    "print(encoder_projection.weight.data.shape)\n",
    "print(encoder_projection.bias.data.shape) # conv_output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.5511]],\n",
       "\n",
       "         [[ 0.5276]]],\n",
       "\n",
       "\n",
       "        [[[-0.1093]],\n",
       "\n",
       "         [[ 0.2632]]],\n",
       "\n",
       "\n",
       "        [[[-0.1005]],\n",
       "\n",
       "         [[-0.5003]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0409]],\n",
       "\n",
       "         [[-0.5255]]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.init.kaiming_normal_(encoder_projection.weight.data, a=0, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "# a: leaky_relu에서 0이하 부분의 음의 기울기, mode = \"fan_out\" or \"fan_in\", nonlinearity = \"relu\" or \"leaky_relu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# weight의 fan_in, fan_out 반환하여 편향(Bias) 초기화 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "_fan_in, fan_out = nn.init._calculate_fan_in_and_fan_out(encoder_projection.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.1903, -0.5756, -0.4199,  0.1565], requires_grad=True)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bound = 1 / math.sqrt(fan_out)\n",
    "nn.init.normal_(encoder_projection.bias, -bound, bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import importlib\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fsdl",
   "language": "python",
   "name": "pytorch"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
